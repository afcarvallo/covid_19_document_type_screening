{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:11:32.108630Z",
     "start_time": "2021-05-24T13:11:32.101110Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:11:44.423143Z",
     "start_time": "2021-05-24T13:11:44.419971Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_inputs(text_list, tokenizer, num_embeddings=512):\n",
    "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t)[:num_embeddings-2], text_list))\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    input_ids = [tokenizer.build_inputs_with_special_tokens(x) for x in input_ids]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=num_embeddings, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:11:47.385741Z",
     "start_time": "2021-05-24T13:11:47.381382Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_attn_masks(input_ids):\n",
    "    attention_masks = []\n",
    "    \n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "        \n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:11:56.035927Z",
     "start_time": "2021-05-24T13:11:56.029277Z"
    }
   },
   "outputs": [],
   "source": [
    "class XLNetForMultiLabelSequenceClassification(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_labels=2):\n",
    "        super(XLNetForMultiLabelSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels       \n",
    "        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
    "        self.classifier = torch.nn.Linear(768, num_labels)\n",
    "        torch.nn.init.xavier_normal_(self.classifier.weight)\n",
    "    \n",
    "    def forward(self, input_ids, token_type_ids=None,attention_mask=None, labels=None):\n",
    "        \n",
    "        last_hidden_state = self.xlnet(input_ids=input_ids,attention_mask=attention_mask,\\\n",
    "                                       token_type_ids=token_type_ids)\n",
    "    \n",
    "        mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
    "        logits = self.classifier(mean_last_hidden_state)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels),labels.view(-1, self.num_labels))\n",
    "            return loss \n",
    " \n",
    "        else:\n",
    "            return logits  \n",
    "\n",
    "    def freeze_xlnet_decoder(self):\n",
    "        for param in self.xlnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_xlnet_decoder(self):\n",
    "        for param in self.xlnet.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def pool_hidden_state(self, last_hidden_state):\n",
    "        last_hidden_state = last_hidden_state[0]\n",
    "        mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
    "        return mean_last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:11:58.749070Z",
     "start_time": "2021-05-24T13:11:58.738927Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(save_path):\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model_state_dict = checkpoint['state_dict']\n",
    "    model = XLNetForMultiLabelSequenceClassification(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    epochs = checkpoint[\"epochs\"]\n",
    "    lowest_eval_loss = checkpoint[\"lowest_eval_loss\"]\n",
    "    train_loss_hist = checkpoint[\"train_loss_hist\"]\n",
    "    valid_loss_hist = checkpoint[\"valid_loss_hist\"]\n",
    "\n",
    "    return model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:14:26.887451Z",
     "start_time": "2021-05-24T13:14:23.907412Z"
    }
   },
   "outputs": [],
   "source": [
    "# LOAD MODEL \n",
    "path = 'path/to/model/xlnet0_uncertainty_iter1.dat'\n",
    "\n",
    "model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:14:30.632551Z",
     "start_time": "2021-05-24T13:14:29.948456Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sampled ids to not consider them in the predictions to prevent data leakage. \n",
    "with open('sampled_ids/cord19_uncertain_pids_iter1.json') as f:\n",
    "    sampled_ids_iter1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:15:23.376514Z",
     "start_time": "2021-05-24T13:14:45.182085Z"
    }
   },
   "outputs": [],
   "source": [
    "# load df CORD19 document types  \n",
    "df_test = pd.read_csv('path/to/dataset/CORD19_full_labels.csv', sep='\\t')\n",
    "\n",
    "# remove sampled ids \n",
    "df_test = df_test[~df_test.pubmed_id.isin(sampled_ids_iter1)]\n",
    "\n",
    "# drop document with no abstract\n",
    "df_test.dropna(subset = ['title', 'abstract'], inplace=True)\n",
    "\n",
    "df_test['document'] = [x + ' ' + y for x,y in zip(df_test.title, df_test.abstract)]\n",
    "\n",
    "# create features and mask columns \n",
    "text_list = df_test[\"document\"].values\n",
    "input_ids = tokenize_inputs(text_list, tokenizer, num_embeddings = 700)\n",
    "attention_masks = create_attn_masks(input_ids)\n",
    "\n",
    "\n",
    "# add input ids and attention masks to the dataframe\n",
    "df_test[\"features\"] = input_ids.tolist()\n",
    "df_test[\"masks\"] = attention_masks\n",
    "\n",
    "\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:54:49.180835Z",
     "start_time": "2021-05-24T13:16:07.559874Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_predictions(model, df, num_labels, device=\"cpu\", batch_size=32):\n",
    "    \n",
    "    num_iter = math.ceil(df.shape[0]/batch_size)\n",
    "    pred_probs = np.array([]).reshape(0, num_labels)\n",
    "    \n",
    "    #embedding_dim = 768\n",
    "    #document_embeddings = np.empty(shape= (num_iter*batch_size, embedding_dim))\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        print('{}/{}'.format(i, num_iter), end='\\r')\n",
    "        \n",
    "        df_subset = df.iloc[i*batch_size:(i+1)*batch_size,:]\n",
    "        X = df_subset[\"features\"].values.tolist()\n",
    "        masks = df_subset[\"masks\"].values.tolist()\n",
    "        X = torch.tensor(X)\n",
    "        masks = torch.tensor(masks, dtype=torch.long)\n",
    "        X = X.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            logits = model(input_ids=X, attention_mask=masks)\n",
    "            logits = logits.sigmoid().detach().cpu().numpy()\n",
    "            pred_probs = np.vstack([pred_probs, logits])\n",
    "            \n",
    "            # add embeddings \n",
    "            #document_embeddings[i][:embedding_dim] = embeddings.cpu().detach()\n",
    "\n",
    "    return pred_probs #, document_embeddings\n",
    "\n",
    "num_labels = 5\n",
    "\n",
    "# give test DF from above \n",
    "pred_probs = generate_predictions(model, df_test, num_labels, device=\"cuda\", batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:55:21.588299Z",
     "start_time": "2021-05-24T13:55:21.585963Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "df_test['pred'] = predictions\n",
    "\n",
    "df_test['probs'] = [row.tolist() for row in pred_probs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:55:27.724368Z",
     "start_time": "2021-05-24T13:55:27.718954Z"
    }
   },
   "outputs": [],
   "source": [
    "gt = []\n",
    "\n",
    "for x in df_test.label:\n",
    "    \n",
    "    if x == 'systematic-review':\n",
    "        gt.append(4)\n",
    "    \n",
    "    elif x == 'primary-not-rct':\n",
    "        gt.append(3)\n",
    "    \n",
    "    elif x == 'primary-rct':\n",
    "        gt.append(2)\n",
    "    \n",
    "    elif x == 'excluded':\n",
    "        gt.append(1)\n",
    "    \n",
    "    elif x == 'broad-synthesis':\n",
    "        gt.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:55:28.280904Z",
     "start_time": "2021-05-24T13:55:28.275946Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['ground_truth'] = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:55:28.775663Z",
     "start_time": "2021-05-24T13:55:28.773239Z"
    }
   },
   "outputs": [],
   "source": [
    "gt = np.array(df_test.ground_truth)\n",
    "preds = np.array(df_test.pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate prediction reports \n",
    "- Confusion matrix\n",
    "- Metrics report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:55:31.323803Z",
     "start_time": "2021-05-24T13:55:31.040701Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('\\nRESULTS XLNET ')\n",
    "\n",
    "array = confusion_matrix(gt, preds)\n",
    "\n",
    "df_cm = pd.DataFrame(array, index = [i for i in [ 'broad-synthesis', 'excluded' , 'primary-rct' , 'primary-not-rct'  , 'systematic-review']],\n",
    "                     \n",
    "                  columns = [i for i in [ 'broad-synthesis', 'excluded' , 'primary-rct' ,'primary-not-rct' , 'systematic-review']])\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "ax = sn.heatmap(df_cm, linewidths = 0.5, xticklabels = True, yticklabels = True, cmap = \"OrRd\", annot = True, fmt = \"d\")\n",
    "\n",
    "for t in ax.texts:\n",
    "    t.set_text('{:,d}'.format(int(t.get_text())))\n",
    "\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T13:55:46.096772Z",
     "start_time": "2021-05-24T13:55:46.090901Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(gt, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
